{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dff0e3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T14:58:43.956218Z",
     "iopub.status.busy": "2026-02-01T14:58:43.955867Z",
     "iopub.status.idle": "2026-02-01T14:58:43.974601Z",
     "shell.execute_reply": "2026-02-01T14:58:43.973339Z",
     "shell.execute_reply.started": "2026-02-01T14:58:43.956184Z"
    },
    "papermill": {
     "duration": 0.005323,
     "end_time": "2026-02-01T15:01:33.666547",
     "exception": false,
     "start_time": "2026-02-01T15:01:33.661224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Norwegian Salmon Health Crisis: 20 Years of Disease vs Production Expansion (2005-2024)\n",
    "\n",
    "##  Executive Summary\n",
    "This analysis examines two decades of disease surveillance in Norwegian Atlantic salmon aquaculture, revealing critical insights about the relationship between industrial expansion and fish health. Despite a 42.5% increase in production licenses, disease patterns show complex dynamics; some infections declined dramatically due to vaccines while others increased, highlighting both successes and ongoing challenges in sustainable aquaculture.\n",
    "\n",
    "##  Project Objectives\n",
    "1. **Quantify** the relationship between production expansion and disease incidence\n",
    "2. **Evaluate** the impact of vaccine introductions on target diseases  \n",
    "3. **Identify** emerging disease threats in modern salmon farming\n",
    "4. **Provide** data-driven recommendations for sustainable aquaculture\n",
    "\n",
    "##  Dataset Overview\n",
    "**Source:** Norwegian Directorate of Fisheries and Veterinary Institute  \n",
    "**Period:** 2005-2024 (20 continuous years)  \n",
    "**Records:** Annual disease case counts + production licenses  \n",
    "**Diseases Tracked:** 8 major salmon pathogens  \n",
    "**File:** `salmon_diseases_2005_2024.csv`\n",
    "\n",
    "### Key Variables:\n",
    "- **Production Indicator:** Annual operational licenses\n",
    "- **Diseases Monitored:**\n",
    "  - ISA (Infectious Salmon Anaemia)\n",
    "  - IPN (Infectious Pancreatic Necrosis)\n",
    "  - PD (Pancreas Disease)\n",
    "  - HSMI (Heart and Skeletal Muscle Inflammation)\n",
    "  - Furunculosis\n",
    "  - BKD (Bacterial Kidney Disease)\n",
    "  - CMS (Cardiomyopathic Syndrome)\n",
    "  - Cold-water vibriosis\n",
    "\n",
    "##  Methodology\n",
    "\n",
    "### Data Processing Pipeline\n",
    "1. **Data Cleaning:** Handle missing values, convert data types\n",
    "2. **Feature Engineering:** Calculate derived metrics\n",
    "3. **Exploratory Analysis:** Visual trends and correlations\n",
    "4. **Statistical Modeling:** Regression and hypothesis testing\n",
    "5. **Interpretation:** Translate findings into insights\n",
    "\n",
    "### Analytical Techniques\n",
    "- **Descriptive Statistics:** Temporal trends and distributions\n",
    "- **Correlation Analysis:** Disease-disease and disease-license relationships\n",
    "- **Regression Models:** Linear, polynomial, and regularized regression\n",
    "- **Comparative Analysis:** Pre/post vaccine periods\n",
    "- **Time Series Analysis:** Lag effects and temporal patterns\n",
    "\n",
    "##  Key Analyses Performed\n",
    "\n",
    "### 1. Disease Trend Visualization\n",
    "- Individual disease trajectories over 20 years\n",
    "- Peak incidence identification for each pathogen\n",
    "- Comparative burden assessment\n",
    "\n",
    "### 2. Production-Disease Relationship\n",
    "- License growth vs. disease incidence correlation\n",
    "- Cases per license density metric\n",
    "- Time-lagged effects analysis\n",
    "\n",
    "### 3. Vaccine Impact Assessment\n",
    "- IPN vaccine (introduced ~2012) effectiveness\n",
    "- PD vaccine (introduced ~2017) outcomes\n",
    "- Statistical significance testing of reductions\n",
    "\n",
    "### 4. Multivariate Analysis\n",
    "- Multiple regression: Total cases = f(Licenses, Year, Licenses¬≤)\n",
    "- Regularized regression for feature importance\n",
    "- Residual diagnostics and model validation\n",
    "\n",
    "##  Key Findings\n",
    "\n",
    "### Success Stories:\n",
    "- **IPN Dramatic Reduction:** Cases dropped from 200+ to <30 annually post-2012 vaccination\n",
    "- **Effective Disease Management:** Overall cases per license trend shows improvement\n",
    "\n",
    "### Emerging Concerns:\n",
    "- **CMS Increase:** Steady rise from ~70 to 150+ cases despite controls\n",
    "- **HSMI Variability:** Fluctuations suggest density-dependent challenges\n",
    "- **Recent BKD Resurgence:** Increase in 2023-2024 warrants attention\n",
    "\n",
    "### Production-Disease Insights:\n",
    "- **Positive Correlation:** CMS and HSMI scale with production\n",
    "- **Decoupled Success:** IPN reduced despite production growth (vaccine effect)\n",
    "- **Mixed Patterns:** Other diseases show complex, non-linear relationships\n",
    "\n",
    "##  Practical Implications\n",
    "\n",
    "### For Salmon Farmers:\n",
    "1. **Vaccine Priority:** Maintain IPN vaccination, consider PD vaccine adoption\n",
    "2. **Density Management:** Monitor CMS and HSMI in high-density operations\n",
    "3. **Surveillance Focus:** Enhanced monitoring for BKD resurgence\n",
    "\n",
    "### For Policymakers:\n",
    "1. **Vaccine Support:** Continue funding for effective immunization programs\n",
    "2. **Sustainable Growth:** Balance production expansion with health safeguards\n",
    "3. **Research Investment:** Target diseases without effective vaccines (CMS, BKD)\n",
    "\n",
    "### For Industry Stakeholders:\n",
    "1. **Risk Assessment:** Consider disease burden in expansion planning\n",
    "2. **Technology Adoption:** Invest in advanced health monitoring systems\n",
    "3. **Collaborative Solutions:** Industry-wide disease management strategies\n",
    "\n",
    "##  Results \n",
    "The analysis generates multiple outputs:\n",
    "\n",
    "### Visualizations:\n",
    "1. `disease_trends.png` - Individual disease trajectories\n",
    "2. `licenses_vs_cases.png` - Production-disease relationship\n",
    "3. `correlation_heatmap.png` - Disease interrelationships\n",
    "3. `disease_contribution.png` - Relative burden of each disease\n",
    "4. Regression diagnostics and model visualizations\n",
    "\n",
    "### Data Outputs:\n",
    "1. `processed_salmon_diseases_data.csv` - Cleaned dataset with calculated metrics\n",
    "2. `disease_summary_statistics.csv` - Aggregated statistics for each disease\n",
    "\n",
    "##  Limitations & Considerations\n",
    "\n",
    "### Data Constraints:\n",
    "- Licenses as production proxy (not actual biomass)\n",
    "- Diagnostic improvements over time may affect case detection\n",
    "- Environmental factors not included in analysis\n",
    "- Possible underreporting in early years\n",
    "\n",
    "### Analytical Limitations:\n",
    "- Small temporal sample (n=20 years)\n",
    "- Correlation does not imply causation\n",
    "- Multiple confounding factors in real world setting\n",
    "- No control group for natural experiment analysis\n",
    "\n",
    "\n",
    "\n",
    "### Prerequisites:\n",
    "Python 3.8+\n",
    "Required libraries: pandas, numpy, matplotlib, seaborn, scikit-learn, statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1762eb-3304-4b2f-b722-faa9fedc9595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (2.3.5)\n",
      "Requirement already satisfied: matplotlib in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (1.17.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: statsmodels in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (0.14.6)\n",
      "Requirement already satisfied: ipykernel in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (7.1.0)\n",
      "Requirement already satisfied: ipywidgets in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (8.1.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (9.8.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (7.1.3)\n",
      "Requirement already satisfied: pyzmq>=25 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in /Users/shreeramghimire/jupyter_fix_env/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Downloading scikit_learn-1.8.0-cp311-cp311-macosx_12_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.3 scikit-learn-1.8.0 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn scipy scikit-learn statsmodels ipykernel ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57396ff3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 6.26259,
     "end_time": "2026-02-01T15:01:39.933702",
     "exception": false,
     "start_time": "2026-02-01T15:01:33.671112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e29d709a",
   "metadata": {
    "papermill": {
     "duration": 0.082169,
     "end_time": "2026-02-01T15:01:40.020414",
     "exception": false,
     "start_time": "2026-02-01T15:01:39.938245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/salmon_diseases_2005_2024.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/salmon_diseases_2005_2024.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDATA OVERVIEW\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_fix_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_fix_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_fix_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_fix_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter_fix_env/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/salmon_diseases_2005_2024.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/salmon_diseases_2005_2024.csv')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "print(f\"\\nYear column type: {type(df['Year'].iloc[0])}\")\n",
    "print(f\"Sample Year values: {df['Year'].head().tolist()}\")\n",
    "\n",
    "try:\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "    df['Year'] = df['Year'].astype(int) \n",
    "    min_year = int(df['Year'].min())\n",
    "    max_year = int(df['Year'].max())\n",
    "    print(f\"\\n‚úÖ Time period: {min_year} - {max_year}\")\n",
    "    print(f\"‚úÖ Number of years: {df['Year'].nunique()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning converting Year: {e}\")\n",
    "    df['Year'] = df['Year'].astype(str).str.extract('(\\d+)')[0]\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "    df['Year'] = df['Year'].astype(int) \n",
    "    \n",
    "    min_year = int(df['Year'].min())\n",
    "    max_year = int(df['Year'].max())\n",
    "    print(f\"\\n‚úÖ Time period (fallback): {min_year} - {max_year}\")\n",
    "    print(f\"‚úÖ Number of years: {df['Year'].nunique()}\")\n",
    "\n",
    "# Verify\n",
    "print(f\"\\n‚úÖ Final Year values (first 10): {df['Year'].head(10).tolist()}\")\n",
    "print(f\"‚úÖ Year data type: {df['Year'].dtype}\")\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "for col in df.columns:\n",
    "    if col != 'Year':  \n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b08e98",
   "metadata": {
    "papermill": {
     "duration": 2.844516,
     "end_time": "2026-02-01T15:01:42.870057",
     "exception": false,
     "start_time": "2026-02-01T15:01:40.025541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Year'] = df['Year'].astype(int) \n",
    "\n",
    "disease_cols = [col for col in df.columns if col not in ['Year', 'Licenses']]\n",
    "df['Total_Cases'] = df[disease_cols].sum(axis=1)\n",
    "df['Cases_per_License'] = df['Total_Cases'] / df['Licenses']\n",
    "df['Production_Index'] = df['Licenses'] / df['Licenses'].iloc[0] * 100\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "major_diseases = ['ISA', 'IPN', 'PD', 'HSMI', 'CMS']\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(major_diseases)))\n",
    "\n",
    "for i, disease in enumerate(major_diseases):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.plot(df['Year'], df[disease], marker='o', linewidth=2, color=colors[i])\n",
    "    plt.xticks(df['Year'][::2])  \n",
    "    plt.title(f'{disease} Cases Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Cases')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    max_year = df.loc[df[disease].idxmax(), 'Year']\n",
    "    plt.axvline(x=max_year, color=colors[i], linestyle='--', alpha=0.5)\n",
    "    plt.text(max_year, df[disease].max(), f' Peak: {max_year}', \n",
    "             verticalalignment='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('disease_trends.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87613631",
   "metadata": {
    "papermill": {
     "duration": 1.217877,
     "end_time": "2026-02-01T15:01:44.096199",
     "exception": false,
     "start_time": "2026-02-01T15:01:42.878322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Year'] = df['Year'].astype(int)\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "ax1.plot(df['Year'], df['Licenses'], 'b-', linewidth=3, marker='s', \n",
    "         markersize=8, label='Licenses')\n",
    "ax1.set_xticks(df['Year'][::2])\n",
    "\n",
    "ax1.set_xlabel('Year', fontsize=12)\n",
    "ax1.set_ylabel('Number of Licenses', color='b', fontsize=12)\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "ax1.set_title('Production Licenses vs. Total Disease Cases (2005-2024)', \n",
    "              fontsize=16, fontweight='bold')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df['Year'], df['Total_Cases'], 'r-', linewidth=3, marker='o', \n",
    "         markersize=8, label='Total Cases')\n",
    "ax2.set_ylabel('Total Disease Cases', color='r', fontsize=12)\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "correlation = df['Licenses'].corr(df['Total_Cases'])\n",
    "ax1.text(0.02, 0.98, f'Correlation: {correlation:.3f}', \n",
    "         transform=ax1.transAxes, fontsize=12,\n",
    "         verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('licenses_vs_cases.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2968db",
   "metadata": {
    "papermill": {
     "duration": 1.155282,
     "end_time": "2026-02-01T15:01:45.261520",
     "exception": false,
     "start_time": "2026-02-01T15:01:44.106238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Year'] = df['Year'].astype(int)\n",
    "disease_cols = [col for col in df.columns if col not in ['Year', 'Licenses']]\n",
    "df['Total_Cases'] = df[disease_cols].sum(axis=1)\n",
    "df['Cases_per_License'] = df['Total_Cases'] / df['Licenses']\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(df['Year'], df['Cases_per_License'], marker='o', linewidth=3, \n",
    "         color='green', markersize=8)\n",
    "plt.fill_between(df['Year'], df['Cases_per_License'], alpha=0.3, color='green')\n",
    "\n",
    "plt.xticks(df['Year'][::2])  \n",
    "\n",
    "plt.title('Disease Cases per License (2005-2024)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Cases per License', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "try:\n",
    "    z = np.polyfit(df['Year'], df['Cases_per_License'].fillna(0), 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df['Year'], p(df['Year']), \"r--\", linewidth=2, \n",
    "             label=f'Trend: y={z[0]:.4f}x + {z[1]:.2f}')\n",
    "    plt.legend(fontsize=11)\n",
    "    \n",
    "    trend_direction = \"increasing\" if z[0] > 0 else \"decreasing\"\n",
    "    trend_text = f\"Trend: {trend_direction} ({abs(z[0]):.4f} per year)\"\n",
    "    \n",
    "    plt.text(0.02, 0.95, trend_text, transform=plt.gca().transAxes,\n",
    "             fontsize=12, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Trend line skipped: {e}\")\n",
    "\n",
    "for i, year in enumerate(df['Year']):\n",
    "    if i % 3 == 0: \n",
    "        plt.annotate(str(year), \n",
    "                    (df['Year'].iloc[i], df['Cases_per_License'].iloc[i]),\n",
    "                    xytext=(5, 5), textcoords='offset points',\n",
    "                    fontsize=9, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cases_per_license.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5f7ea",
   "metadata": {
    "papermill": {
     "duration": 0.038118,
     "end_time": "2026-02-01T15:01:45.311489",
     "exception": false,
     "start_time": "2026-02-01T15:01:45.273371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vaccine_periods = {\n",
    "    'IPN_vaccine': 2012,  \n",
    "    'PD_vaccine': 2017,  \n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VACCINE IMPACT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for vaccine, year in vaccine_periods.items():\n",
    "    disease = vaccine.split('_')[0]  \n",
    "    \n",
    "    if disease in df.columns:\n",
    "        before = df[df['Year'] < year][disease].mean()\n",
    "        after = df[df['Year'] >= year][disease].mean()\n",
    "        change = ((after - before) / before) * 100\n",
    "        \n",
    "        print(f\"\\n{disease} (Vaccine ~{year}):\")\n",
    "        print(f\"  Before ({df['Year'].min()}-{year-1}): {before:.1f} avg cases\")\n",
    "        print(f\"  After ({year}-{df['Year'].max()}): {after:.1f} avg cases\")\n",
    "        print(f\"  Change: {change:.1f}%\")\n",
    "        \n",
    "        # Statistical test\n",
    "        t_stat, p_value = stats.ttest_ind(\n",
    "            df[df['Year'] < year][disease], \n",
    "            df[df['Year'] >= year][disease]\n",
    "        )\n",
    "        print(f\"  t-test p-value: {p_value:.4f}\")\n",
    "        print(f\"  Significant (p<0.05): {'Yes' if p_value < 0.05 else 'No'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34cfdbb",
   "metadata": {
    "papermill": {
     "duration": 1.426889,
     "end_time": "2026-02-01T15:01:46.750346",
     "exception": false,
     "start_time": "2026-02-01T15:01:45.323457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_matrix = df[disease_cols + ['Licenses']].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', \n",
    "            center=0, fmt='.2f', square=True, linewidths=1)\n",
    "\n",
    "plt.title('Correlation Matrix: Diseases and Licenses', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392f833",
   "metadata": {
    "papermill": {
     "duration": 1.040692,
     "end_time": "2026-02-01T15:01:47.812380",
     "exception": false,
     "start_time": "2026-02-01T15:01:46.771688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_cases_all_years = df[disease_cols].sum().sum()\n",
    "disease_contribution = df[disease_cols].sum() / total_cases_all_years * 100\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "disease_contribution.sort_values(ascending=False).plot(kind='bar', color='steelblue')\n",
    "plt.title('Percentage Contribution of Each Disease (2005-2024)', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Disease')\n",
    "plt.ylabel('Percentage of Total Cases (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(disease_contribution.sort_values(ascending=False)):\n",
    "    plt.text(i, v + 0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('disease_contribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04c621",
   "metadata": {
    "papermill": {
     "duration": 0.042339,
     "end_time": "2026-02-01T15:01:47.869465",
     "exception": false,
     "start_time": "2026-02-01T15:01:47.827126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_periods = pd.DataFrame({\n",
    "    'Period': ['Early (2005-2010)', 'Middle (2011-2017)', 'Recent (2018-2024)'],\n",
    "    'Years': ['2005-2010', '2011-2017', '2018-2024'],\n",
    "    'Start_Year': [2005, 2011, 2018],\n",
    "    'End_Year': [2010, 2017, 2024]\n",
    "})\n",
    "\n",
    "period_data = []\n",
    "\n",
    "for _, period in df_periods.iterrows():\n",
    "    mask = (df['Year'] >= period['Start_Year']) & (df['Year'] <= period['End_Year'])\n",
    "    period_df_subset = df.loc[mask, disease_cols + ['Licenses', 'Total_Cases', 'Cases_per_License']]\n",
    "    period_avg = period_df_subset.mean().to_dict()  \n",
    "    period_avg['Period'] = period['Period']\n",
    "    period_avg['Year_Range'] = period['Years']\n",
    "    \n",
    "    period_data.append(period_avg)\n",
    "\n",
    "period_df = pd.DataFrame(period_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERIOD COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "display_cols = ['Period', 'Year_Range', 'Licenses', 'Total_Cases', 'Cases_per_License']\n",
    "display_cols = [col for col in display_cols if col in period_df.columns]\n",
    "\n",
    "for disease in major_diseases:\n",
    "    if disease in period_df.columns:\n",
    "        display_cols.append(disease)\n",
    "\n",
    "print(period_df[display_cols].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfb60f",
   "metadata": {
    "papermill": {
     "duration": 0.09219,
     "end_time": "2026-02-01T15:01:47.978555",
     "exception": false,
     "start_time": "2026-02-01T15:01:47.886365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n SIMPLE LINEAR REGRESSION (Each Disease vs Licenses)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.fillna(0)  # Replace NaN with 0 for disease counts\n",
    "\n",
    "regression_results = []\n",
    "X = df_clean['Licenses'].values.reshape(-1, 1)\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "for disease in disease_cols:\n",
    "    if disease not in df_clean.columns:\n",
    "        print(f\"Skipping {disease} - column not found\")\n",
    "        continue\n",
    "    \n",
    "    y = df_clean[disease].values\n",
    "    \n",
    "    # Skip if all values are NaN or zero\n",
    "    if np.all(np.isnan(y)) or np.all(y == 0):\n",
    "        print(f\"Skipping {disease} - all values are zero or NaN\")\n",
    "        continue\n",
    "    y = np.nan_to_num(y, nan=0.0)\n",
    "    scaler_y = StandardScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_scaled, y_scaled)\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    r2 = r2_score(y_scaled, y_pred)\n",
    "    slope = model.coef_[0]\n",
    "    X_sm = sm.add_constant(X_scaled)\n",
    "    model_sm = sm.OLS(y_scaled, X_sm).fit()\n",
    "    p_value = model_sm.pvalues[1]\n",
    "    direction = \"increases\" if slope > 0 else \"decreases\"\n",
    "    \n",
    "    regression_results.append({\n",
    "        'Disease': disease,\n",
    "        'Slope': slope,\n",
    "        'R2': r2,\n",
    "        'P_Value': p_value,\n",
    "        'Significant': p_value < 0.05,\n",
    "        'Interpretation': f\"For each SD in licenses, {disease} {direction} by {abs(slope):.3f} SD\"\n",
    "    })\n",
    "\n",
    "    significance = \"‚úì\" if p_value < 0.05 else \"‚úó\"\n",
    "    print(f\"\\n{disease}:\")\n",
    "    print(f\"  Slope (Œ≤): {slope:.4f}\")\n",
    "    print(f\"  R¬≤: {r2:.4f}\")\n",
    "    print(f\"  p-value: {p_value:.4f} {significance}\")\n",
    "if regression_results:\n",
    "    results_df = pd.DataFrame(regression_results)\n",
    "    results_df = results_df.sort_values('R2', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä REGRESSION RESULTS SUMMARY (Sorted by R¬≤)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(results_df[['Disease', 'Slope', 'R2', 'P_Value', 'Significant']].round(4).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo valid regression results to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c83b7",
   "metadata": {
    "papermill": {
     "duration": 2.866358,
     "end_time": "2026-02-01T15:01:50.860334",
     "exception": false,
     "start_time": "2026-02-01T15:01:47.993976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_clean = df.fillna(0)\n",
    "\n",
    "if 'results_df' in locals() and len(results_df) > 0:\n",
    "    top_diseases = results_df.nlargest(4, 'R2')['Disease'].tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    X_clean = df_clean['Licenses'].values.reshape(-1, 1)\n",
    "    X_scaled_clean = StandardScaler().fit_transform(X_clean)\n",
    "    \n",
    "    for idx, disease in enumerate(top_diseases):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        y = df_clean[disease].values\n",
    "        if np.all(y == 0):\n",
    "            ax.text(0.5, 0.5, f'No data for {disease}', \n",
    "                    transform=ax.transAxes, ha='center', va='center')\n",
    "            continue\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_scaled_clean, y)\n",
    "        X_vals = np.linspace(df_clean['Licenses'].min(), df_clean['Licenses'].max(), 100).reshape(-1, 1)\n",
    "        X_vals_scaled = StandardScaler().fit_transform(X_vals)\n",
    "        y_line = model.predict(X_vals_scaled)\n",
    "    \n",
    "        ax.scatter(df_clean['Licenses'], y, alpha=0.7, s=80, edgecolors='k', label='Actual')\n",
    "        ax.plot(X_vals, y_line, 'r-', linewidth=2, \n",
    "                label=f'Regression (R¬≤={results_df[results_df[\"Disease\"]==disease][\"R2\"].values[0]:.3f})')\n",
    "        \n",
    "\n",
    "        for i, year in enumerate(df_clean['Year']):\n",
    "            if i % 4 == 0:  # Label every 4th year\n",
    "                ax.annotate(str(int(year)), \n",
    "                           (df_clean['Licenses'].iloc[i], y[i]),\n",
    "                           xytext=(5, 5), textcoords='offset points', \n",
    "                           fontsize=8, alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Number of Licenses', fontsize=11)\n",
    "        ax.set_ylabel(f'{disease} Cases', fontsize=11)\n",
    "        disease_stats = results_df[results_df['Disease'] == disease]\n",
    "        if not disease_stats.empty:\n",
    "            slope = disease_stats['Slope'].values[0]\n",
    "            p_value = disease_stats['P_Value'].values[0]\n",
    "            ax.set_title(f'{disease} vs Licenses\\nŒ≤={slope:.3f}, p={p_value:.4f}')\n",
    "        \n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Top 4 Diseases by Regression Fit with Licenses', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('regression_top_diseases.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"results_df not found. Run regression analysis first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c846c23",
   "metadata": {
    "papermill": {
     "duration": 0.059913,
     "end_time": "2026-02-01T15:01:50.939235",
     "exception": false,
     "start_time": "2026-02-01T15:01:50.879322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" MULTIPLE REGRESSION: Predicting Total Cases\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_clean = df.fillna(0)\n",
    "\n",
    "X_multi = df_clean[['Licenses']].copy()\n",
    "if X_multi['Licenses'].isnull().any():\n",
    "    print(\"‚ö†Ô∏è Warning: Licenses column contains NaN after cleaning\")\n",
    "    X_multi['Licenses'] = X_multi['Licenses'].fillna(X_multi['Licenses'].mean())\n",
    "X_multi['Year_Normalized'] = (df_clean['Year'] - df_clean['Year'].mean()) / (df_clean['Year'].max() - df_clean['Year'].min())\n",
    "\n",
    "X_multi['Licenses_Squared'] = X_multi['Licenses'] ** 2\n",
    "if 'Total_Cases' not in df_clean.columns:\n",
    "    disease_cols_clean = [col for col in df_clean.columns if col not in ['Year', 'Licenses']]\n",
    "    y_multi = df_clean[disease_cols_clean].sum(axis=1).values\n",
    "else:\n",
    "    y_multi = df_clean['Total_Cases'].values\n",
    "print(f\"Checking for NaN in features:\")\n",
    "for col in X_multi.columns:\n",
    "    nan_count = X_multi[col].isnull().sum()\n",
    "    print(f\"  {col}: {nan_count} NaN values\")\n",
    "X_multi_clean = X_multi.fillna(0)\n",
    "y_multi_clean = np.nan_to_num(y_multi, nan=0)\n",
    "\n",
    "scaler_multi = StandardScaler()\n",
    "X_multi_scaled = scaler_multi.fit_transform(X_multi_clean)\n",
    "\n",
    "try:\n",
    "    multi_model = LinearRegression()\n",
    "    multi_model.fit(X_multi_scaled, y_multi_clean)\n",
    "    y_multi_pred = multi_model.predict(X_multi_scaled)\n",
    "    r2_multi = r2_score(y_multi_clean, y_multi_pred)\n",
    "    mse_multi = mean_squared_error(y_multi_clean, y_multi_pred)\n",
    "    mae_multi = mean_absolute_error(y_multi_clean, y_multi_pred)\n",
    "    \n",
    "    print(f\"\\nMultiple Regression Results (Total Cases = f(Licenses, Year, Licenses¬≤)):\")\n",
    "    print(f\"R¬≤: {r2_multi:.4f}\")\n",
    "    print(f\"MSE: {mse_multi:.2f}\")\n",
    "    print(f\"MAE: {mae_multi:.2f}\")\n",
    "    print(f\"\\nCoefficients:\")\n",
    "    feature_names = ['Licenses', 'Year_Normalized', 'Licenses_Squared']\n",
    "    for i, (name, coef) in enumerate(zip(feature_names, multi_model.coef_)):\n",
    "        print(f\"  {name}: {coef:.4f}\")\n",
    "    print(f\"  Intercept: {multi_model.intercept_:.2f}\")\n",
    "    try:\n",
    "        X_multi_sm = sm.add_constant(X_multi_scaled)\n",
    "        model_multi_sm = sm.OLS(y_multi_clean, X_multi_sm).fit()\n",
    "        print(\"\\nDetailed Regression Summary (first few lines):\")\n",
    "        print(model_multi_sm.summary().tables[1])\n",
    "    except:\n",
    "        print(\"\\n‚ö†Ô∏è Could not generate detailed statsmodels summary\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error in multiple regression: {e}\")\n",
    "    print(\"Trying simpler approach...\")\n",
    "    X_simple = df_clean['Licenses'].values.reshape(-1, 1)\n",
    "    y_simple = y_multi_clean   \n",
    "    simple_model = LinearRegression()\n",
    "    simple_model.fit(X_simple, y_simple)\n",
    "    r2_simple = simple_model.score(X_simple, y_simple)\n",
    "    \n",
    "    print(f\"\\nSimple Linear Regression (Total Cases ~ Licenses):\")\n",
    "    print(f\"R¬≤: {r2_simple:.4f}\")\n",
    "    print(f\"Slope: {simple_model.coef_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f63c05",
   "metadata": {
    "papermill": {
     "duration": 0.802135,
     "end_time": "2026-02-01T15:01:51.761287",
     "exception": false,
     "start_time": "2026-02-01T15:01:50.959152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " TIME SERIES REGRESSION: Impact of Previous Year's Licenses\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m TIME SERIES REGRESSION: Impact of Previous Year\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms Licenses\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_clean = \u001b[43mdf\u001b[49m.fillna(\u001b[32m0\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mTotal_Cases\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df_clean.columns:\n\u001b[32m      9\u001b[39m     disease_cols_lag = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_clean.columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLicenses\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" TIME SERIES REGRESSION: Impact of Previous Year's Licenses\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "df_clean = df.fillna(0)\n",
    "\n",
    "if 'Total_Cases' not in df_clean.columns:\n",
    "    disease_cols_lag = [col for col in df_clean.columns if col not in ['Year', 'Licenses']]\n",
    "    df_clean['Total_Cases'] = df_clean[disease_cols_lag].sum(axis=1)\n",
    "\n",
    "df_lag = df_clean.copy()\n",
    "for col in ['Licenses', 'Total_Cases']:\n",
    "    df_lag[f'{col}_lag1'] = df_lag[col].shift(1)\n",
    "\n",
    "df_lag_clean = df_lag.dropna().copy()\n",
    "\n",
    "X_lag = df_lag_clean[['Licenses_lag1']]\n",
    "y_lag = df_lag_clean['Total_Cases']\n",
    "if len(X_lag) > 0 and len(y_lag) > 0:\n",
    "    lag_model = LinearRegression()\n",
    "    lag_model.fit(X_lag, y_lag)\n",
    "    y_lag_pred = lag_model.predict(X_lag)\n",
    "    \n",
    "    r2_lag = r2_score(y_lag, y_lag_pred)\n",
    "    lag_slope = lag_model.coef_[0]\n",
    "    lag_intercept = lag_model.intercept_\n",
    "    \n",
    "    print(f\"\\nRegression: Current Year Total Cases = f(Previous Year Licenses)\")\n",
    "    print(f\"Slope: {lag_slope:.4f}\")\n",
    "    print(f\"Intercept: {lag_intercept:.2f}\")\n",
    "    print(f\"R¬≤: {r2_lag:.4f}\")\n",
    "    print(f\"Interpretation: For each additional license last year, total cases increase by {lag_slope:.2f} this year\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X_lag, y_lag, alpha=0.7, s=100, edgecolors='k', label='Actual Data')\n",
    "   \n",
    "    x_line = np.array([[X_lag.min().iloc[0]], [X_lag.max().iloc[0]]])\n",
    "    y_line = lag_model.predict(x_line)\n",
    "    plt.plot(x_line, y_line, 'r-', linewidth=2, label=f'Regression (R¬≤={r2_lag:.3f})')\n",
    "    \n",
    "    plt.xlabel('Previous Year Licenses', fontsize=12)\n",
    "    plt.ylabel('Current Year Total Cases', fontsize=12)\n",
    "    plt.title('Time Series Regression: Lag Effect of Licenses on Disease Cases', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('time_series_lag_regression.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Not enough data for lag regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322e4326",
   "metadata": {
    "papermill": {
     "duration": 0.077247,
     "end_time": "2026-02-01T15:01:51.867901",
     "exception": false,
     "start_time": "2026-02-01T15:01:51.790654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " REGULARIZED REGRESSION: Ridge & Lasso Comparison\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m REGULARIZED REGRESSION: Ridge & Lasso Comparison\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_clean = \u001b[43mdf\u001b[49m.fillna(\u001b[32m0\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mTotal_Cases\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df_clean.columns:\n\u001b[32m      6\u001b[39m     actual_disease_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_clean.columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLicenses\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCases_per_License\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mProduction_Index\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" REGULARIZED REGRESSION: Ridge & Lasso Comparison\")\n",
    "print(\"=\" * 60)\n",
    "df_clean = df.fillna(0)\n",
    "if 'Total_Cases' not in df_clean.columns:\n",
    "    actual_disease_cols = [col for col in df_clean.columns if col not in ['Year', 'Licenses', 'Cases_per_License', 'Production_Index']]\n",
    "    df_clean['Total_Cases'] = df_clean[actual_disease_cols].sum(axis=1)\n",
    "    disease_cols_clean = actual_disease_cols\n",
    "else:\n",
    "    disease_cols_clean = [col for col in disease_cols if col not in ['Total_Cases', 'Cases_per_License', 'Production_Index']]\n",
    "X_all = df_clean[disease_cols_clean].copy()\n",
    "y_all = df_clean['Total_Cases'].values\n",
    "\n",
    "print(f\"Using {len(disease_cols_clean)} diseases as predictors\")\n",
    "print(f\"Sample size: {len(X_all)} years\")\n",
    "\n",
    "if X_all.isnull().any().any():\n",
    "    print(\"‚ö†Ô∏è X_all contains NaN, filling with 0\")\n",
    "    X_all = X_all.fillna(0)\n",
    "\n",
    "if np.isnan(y_all).any():\n",
    "    print(\"‚ö†Ô∏è y_all contains NaN, filling with 0\")\n",
    "    y_all = np.nan_to_num(y_all)\n",
    "\n",
    "scaler_all = StandardScaler()\n",
    "X_all_scaled = scaler_all.fit_transform(X_all)\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_all_scaled, y_all)\n",
    "\n",
    "lasso = Lasso(alpha=0.1, max_iter=5000)  # Increased max_iter for convergence\n",
    "lasso.fit(X_all_scaled, y_all)\n",
    "\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'Disease': disease_cols_clean,\n",
    "    'Ridge_Coefficient': ridge.coef_,\n",
    "    'Lasso_Coefficient': lasso.coef_,\n",
    "    'Absolute_Importance_Ridge': np.abs(ridge.coef_),\n",
    "    'Absolute_Importance_Lasso': np.abs(lasso.coef_)\n",
    "})\n",
    "\n",
    "coef_comparison = coef_comparison.sort_values('Absolute_Importance_Ridge', ascending=False)\n",
    "\n",
    "print(\"\\nTop Predictors of Total Cases (Regularized Regression):\")\n",
    "print(coef_comparison[['Disease', 'Ridge_Coefficient', 'Lasso_Coefficient']].round(4).to_string(index=False))\n",
    "\n",
    "\n",
    "print(\"\\n Interpretation:\")\n",
    "print(\"‚Ä¢ Ridge coefficients: All diseases contribute (some penalized)\")\n",
    "print(\"‚Ä¢ Lasso coefficients: Only important diseases selected (others set to 0)\")\n",
    "print(\"‚Ä¢ Positive coefficient: Disease contributes to total cases\")\n",
    "print(\"‚Ä¢ Negative coefficient: Disease inversely related to total cases\")\n",
    "\n",
    "\n",
    "selected_by_lasso = coef_comparison[coef_comparison['Lasso_Coefficient'] != 0]['Disease'].tolist()\n",
    "print(f\"\\n Diseases selected by Lasso (non-zero coefficients): {selected_by_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e01ce15",
   "metadata": {
    "papermill": {
     "duration": 0.987243,
     "end_time": "2026-02-01T15:01:52.875417",
     "exception": false,
     "start_time": "2026-02-01T15:01:51.888174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " POLYNOMIAL REGRESSION: Capturing Non-linear Effects\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m POLYNOMIAL REGRESSION: Capturing Non-linear Effects\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[32m      6\u001b[39m df_clean = df.fillna(\u001b[32m0\u001b[39m)\n\u001b[32m      7\u001b[39m disease_example = \u001b[33m'\u001b[39m\u001b[33mIPN\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" POLYNOMIAL REGRESSION: Capturing Non-linear Effects\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "df_clean = df.fillna(0)\n",
    "disease_example = 'IPN'\n",
    "\n",
    "if disease_example not in df_clean.columns:\n",
    "    print(f\"‚ö†Ô∏è {disease_example} not found in data\")\n",
    "    # Try another disease\n",
    "    disease_example = 'CMS' if 'CMS' in df_clean.columns else df_clean.columns[2]\n",
    "\n",
    "print(f\"Analyzing {disease_example} vs Licenses\")\n",
    "\n",
    "X_poly = df_clean['Licenses'].values.reshape(-1, 1)\n",
    "y_poly = df_clean[disease_example].values\n",
    "\n",
    "if np.all(y_poly == 0):\n",
    "    print(f\"‚ö†Ô∏è All values for {disease_example} are zero\")\n",
    "    # Find a disease with non-zero values\n",
    "    for col in df_clean.columns:\n",
    "        if col not in ['Year', 'Licenses'] and not np.all(df_clean[col] == 0):\n",
    "            disease_example = col\n",
    "            y_poly = df_clean[disease_example].values\n",
    "            print(f\"Using {disease_example} instead\")\n",
    "            break\n",
    "degrees = [1, 2, 3, 4]\n",
    "poly_results = []\n",
    "\n",
    "for degree in degrees:\n",
    "    try:\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly_transformed = poly.fit_transform(X_poly)\n",
    "        \n",
    "        model_poly = LinearRegression()\n",
    "        model_poly.fit(X_poly_transformed, y_poly)\n",
    "        y_poly_pred = model_poly.predict(X_poly_transformed)\n",
    "        \n",
    "        r2_poly = r2_score(y_poly, y_poly_pred)\n",
    "        poly_results.append({\n",
    "            'Degree': degree,\n",
    "            'R2': r2_poly,\n",
    "            'Model': model_poly,\n",
    "            'Poly': poly\n",
    "        })\n",
    "        \n",
    "        print(f\"Degree {degree}: R¬≤ = {r2_poly:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Degree {degree} failed: {e}\")\n",
    "\n",
    "if poly_results:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    X_sorted = np.sort(X_poly, axis=0)\n",
    "    \n",
    "    colors = ['red', 'blue', 'green', 'orange']\n",
    "    \n",
    "    for idx, result in enumerate(poly_results):\n",
    "        if idx < len(colors):\n",
    "            color = colors[idx]\n",
    "        else:\n",
    "            color = 'gray'\n",
    "            \n",
    "        X_plot = result['Poly'].fit_transform(X_sorted)\n",
    "        y_plot = result['Model'].predict(X_plot)\n",
    "        \n",
    "        plt.plot(X_sorted, y_plot, '--', linewidth=2, color=color,\n",
    "                 label=f'Degree {result[\"Degree\"]} (R¬≤={result[\"R2\"]:.3f})')\n",
    "    \n",
    "    plt.scatter(df_clean['Licenses'], y_poly, s=100, alpha=0.7, \n",
    "                edgecolors='k', label='Actual Data', zorder=5)\n",
    "    \n",
    "    plt.xlabel('Licenses', fontsize=12)\n",
    "    plt.ylabel(f'{disease_example} Cases', fontsize=12)\n",
    "    plt.title(f'Polynomial Regression: {disease_example} vs Licenses', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('polynomial_regression.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    best_result = max(poly_results, key=lambda x: x['R2'])\n",
    "    print(f\"\\n‚úÖ Best fit: Degree {best_result['Degree']} with R¬≤ = {best_result['R2']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå No polynomial models were successfully fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff2df10",
   "metadata": {
    "papermill": {
     "duration": 2.084172,
     "end_time": "2026-02-01T15:01:54.984214",
     "exception": false,
     "start_time": "2026-02-01T15:01:52.900042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " REGRESSION DIAGNOSTICS: Residual Analysis\n",
      "============================================================\n",
      "‚ö†Ô∏è Multiple regression results not found. Running simple regression...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33my_multi\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33my_multi_pred\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ö†Ô∏è Multiple regression results not found. Running simple regression...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     df_clean = \u001b[43mdf\u001b[49m.fillna(\u001b[32m0\u001b[39m)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mTotal_Cases\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df_clean.columns:\n\u001b[32m     10\u001b[39m         disease_cols_diag = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_clean.columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLicenses\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" REGRESSION DIAGNOSTICS: Residual Analysis\")\n",
    "print(\"=\" * 60)\n",
    "if 'y_multi' not in locals() or 'y_multi_pred' not in locals():\n",
    "    print(\"‚ö†Ô∏è Multiple regression results not found. Running simple regression...\")\n",
    "\n",
    "    df_clean = df.fillna(0)\n",
    " \n",
    "    if 'Total_Cases' not in df_clean.columns:\n",
    "        disease_cols_diag = [col for col in df_clean.columns if col not in ['Year', 'Licenses']]\n",
    "        df_clean['Total_Cases'] = df_clean[disease_cols_diag].sum(axis=1)\n",
    "   \n",
    "    X_simple = df_clean['Licenses'].values.reshape(-1, 1)\n",
    "    y_multi = df_clean['Total_Cases'].values\n",
    "    \n",
    "    simple_model = LinearRegression()\n",
    "    simple_model.fit(X_simple, y_multi)\n",
    "    y_multi_pred = simple_model.predict(X_simple)\n",
    "    \n",
    "    print(f\"‚úÖ Using simple regression (Total Cases ~ Licenses)\")\n",
    "    print(f\"   R¬≤ = {simple_model.score(X_simple, y_multi):.4f}\")\n",
    "\n",
    "residuals = y_multi - y_multi_pred\n",
    "\n",
    "print(f\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean: {residuals.mean():.2f}\")\n",
    "print(f\"  Std Dev: {residuals.std():.2f}\")\n",
    "print(f\"  Min: {residuals.min():.2f}\")\n",
    "print(f\"  Max: {residuals.max():.2f}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].scatter(y_multi_pred, residuals, alpha=0.7, s=80, edgecolors='k')\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_xlabel('Fitted Values', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Residuals', fontsize=11)\n",
    "axes[0, 0].set_title('Residuals vs Fitted Values', fontsize=12)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "try:\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "    axes[0, 1].set_title('Q-Q Plot of Residuals', fontsize=12)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "except:\n",
    "    axes[0, 1].text(0.5, 0.5, 'Q-Q Plot Failed', \n",
    "                    transform=axes[0, 1].transAxes, ha='center', va='center')\n",
    "    axes[0, 1].set_title('Q-Q Plot (Failed)', fontsize=12)\n",
    "\n",
    "df_clean = df.fillna(0)\n",
    "if len(df_clean) == len(residuals):\n",
    "    axes[1, 0].scatter(df_clean['Year'], residuals, alpha=0.7, s=80, edgecolors='k')\n",
    "    axes[1, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[1, 0].set_xlabel('Year', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('Residuals', fontsize=11)\n",
    "    axes[1, 0].set_title('Residuals vs Time', fontsize=12)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'Year data mismatch', \n",
    "                    transform=axes[1, 0].transAxes, ha='center', va='center')\n",
    "    axes[1, 0].set_title('Residuals vs Time (Data Issue)', fontsize=12)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].hist(residuals, bins=10, edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(x=0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Residuals', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 1].set_title('Distribution of Residuals', fontsize=12)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Regression Diagnostics: Residual Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('regression_diagnostics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Regression Diagnostics Check:\")\n",
    "print(\"1. Residuals vs Fitted: Should show random scatter (no pattern)\")\n",
    "print(\"2. Q-Q Plot: Points should follow straight line (normality)\")\n",
    "print(\"3. Residuals vs Time: Should show no trend over time\")\n",
    "print(\"4. Histogram: Should be roughly bell-shaped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411a9d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T15:01:55.034243Z",
     "iopub.status.busy": "2026-02-01T15:01:55.033266Z",
     "iopub.status.idle": "2026-02-01T15:01:55.040839Z",
     "shell.execute_reply": "2026-02-01T15:01:55.039466Z"
    },
    "papermill": {
     "duration": 0.035034,
     "end_time": "2026-02-01T15:01:55.043223",
     "exception": false,
     "start_time": "2026-02-01T15:01:55.008189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " KEY INSIGHTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "üî¥ CRITICAL FINDINGS:\n",
      "1. Production increased 42% but disease patterns varied\n",
      "2. IPN declined dramatically (vaccine success story)\n",
      "3. CMS increased despite controls (emerging concern)\n",
      "4. HSMI & PD show mixed patterns\n",
      "\n",
      "üü° REGRESSION INSIGHTS:\n",
      "‚Ä¢ Licenses explain 30-70% of disease variance\n",
      "‚Ä¢ Each disease has unique relationship with production\n",
      "‚Ä¢ Time effects important (vaccine introductions matter)\n",
      "\n",
      "üü¢ RECOMMENDATIONS:\n",
      "1. Continue IPN vaccination programs\n",
      "2. Develop better CMS management strategies\n",
      "3. Monitor density effects on HSMI/PD\n",
      "4. Regular regression analysis for early warnings\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n KEY INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüî¥ CRITICAL FINDINGS:\")\n",
    "print(\"1. Production increased 42% but disease patterns varied\")\n",
    "print(\"2. IPN declined dramatically (vaccine success story)\")\n",
    "print(\"3. CMS increased despite controls (emerging concern)\")\n",
    "print(\"4. HSMI & PD show mixed patterns\")\n",
    "\n",
    "print(\"\\nüü° REGRESSION INSIGHTS:\")\n",
    "print(\"‚Ä¢ Licenses explain 30-70% of disease variance\")\n",
    "print(\"‚Ä¢ Each disease has unique relationship with production\")\n",
    "print(\"‚Ä¢ Time effects important (vaccine introductions matter)\")\n",
    "\n",
    "print(\"\\nüü¢ RECOMMENDATIONS:\")\n",
    "print(\"1. Continue IPN vaccination programs\")\n",
    "print(\"2. Develop better CMS management strategies\")\n",
    "print(\"3. Monitor density effects on HSMI/PD\")\n",
    "print(\"4. Regular regression analysis for early warnings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d368b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T15:01:55.093413Z",
     "iopub.status.busy": "2026-02-01T15:01:55.093104Z",
     "iopub.status.idle": "2026-02-01T15:01:55.127752Z",
     "shell.execute_reply": "2026-02-01T15:01:55.126939Z"
    },
    "papermill": {
     "duration": 0.061915,
     "end_time": "2026-02-01T15:01:55.129891",
     "exception": false,
     "start_time": "2026-02-01T15:01:55.067976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MAIN ANALYSIS FILES :\n",
      "  ‚úÖ disease_trends.png                       (597.8 KB)\n",
      "  ‚úÖ licenses_vs_cases.png                    (337.0 KB)\n",
      "  ‚úÖ correlation_heatmap.png                  (370.1 KB)\n",
      "  ‚úÖ disease_contribution.png                 (227.4 KB)\n",
      "  ‚úÖ disease_summary_statistics.csv           (0.7 KB)\n",
      "  ‚úÖ processed_salmon_diseases_data.csv       (1.8 KB)\n",
      "\n",
      " REGRESSION ANALYSIS FILES:\n",
      "  ‚úÖ regression_top_diseases.png              (682.2 KB)\n",
      "  ‚úÖ polynomial_regression.png                (354.5 KB)\n",
      "  ‚úÖ regression_diagnostics.png               (412.2 KB)\n",
      "  ‚úÖ time_series_lag_regression.png           (210.6 KB)\n",
      "\n",
      "============================================================\n",
      "üì¶ DOWNLOAD \n",
      "============================================================\n",
      "‚ö†Ô∏è Could not create zip file: name 'files_found' is not defined\n",
      "üìÅ Files are in: /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    z = np.polyfit(df['Year'], df['Cases_per_License'], 1)\n",
    "except:\n",
    "    z = [0, 0] \n",
    "\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Total_Cases_2005_2024': df[disease_cols].sum(),\n",
    "    'Average_Cases_per_Year': df[disease_cols].mean(),\n",
    "    'Max_Cases_Year': df.loc[df[disease_cols].idxmax(), 'Year'].values,\n",
    "    'Max_Cases': df[disease_cols].max(),\n",
    "    'Correlation_with_Licenses': df[disease_cols].apply(lambda x: x.corr(df['Licenses']))\n",
    "})\n",
    "\n",
    "summary_stats.to_csv('disease_summary_statistics.csv')\n",
    "df.to_csv('processed_salmon_diseases_data.csv', index=False)\n",
    "\n",
    "import os\n",
    "\n",
    "all_files = [\n",
    "    'disease_trends.png',\n",
    "    'licenses_vs_cases.png',\n",
    "    'correlation_heatmap.png',\n",
    "    'disease_contribution.png',\n",
    "    'disease_summary_statistics.csv',\n",
    "    'processed_salmon_diseases_data.csv',\n",
    "    'regression_top_diseases.png',\n",
    "    'polynomial_regression.png',\n",
    "    'regression_diagnostics.png',\n",
    "    'time_series_lag_regression.png'\n",
    "]\n",
    "\n",
    "print(\"\\n MAIN ANALYSIS FILES :\")\n",
    "main_files_names = [\n",
    "    'disease_trends.png',\n",
    "    'licenses_vs_cases.png', \n",
    "    'correlation_heatmap.png',\n",
    "    'disease_contribution.png',\n",
    "    'disease_summary_statistics.csv',\n",
    "    'processed_salmon_diseases_data.csv'\n",
    "]\n",
    "\n",
    "for file in main_files_names:\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file) / 1024  \n",
    "        print(f\"  ‚úÖ {file:40} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {file:40} (not found)\")\n",
    "\n",
    "print(\"\\n REGRESSION ANALYSIS FILES:\")\n",
    "regression_files_names = [\n",
    "    'regression_top_diseases.png',\n",
    "    'polynomial_regression.png',\n",
    "    'regression_diagnostics.png',\n",
    "    'time_series_lag_regression.png'\n",
    "]\n",
    "\n",
    "regression_found = 0\n",
    "for file in regression_files_names:\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file) / 1024  # Size in KB\n",
    "        print(f\"  ‚úÖ {file:40} ({size:.1f} KB)\")\n",
    "        regression_found += 1\n",
    "    else:\n",
    "        print(f\"  ‚ùå {file:40} (not found)\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üì¶ DOWNLOAD \")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    import shutil\n",
    "    import zipfile\n",
    "    if files_found:\n",
    "        zip_filename = 'salmon_analysis_results.zip'\n",
    "        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "            for file in files_found:\n",
    "                zipf.write(file)\n",
    "        \n",
    "        zip_size = os.path.getsize(zip_filename) / 1024  # KB\n",
    "        print(f\"‚úÖ File: {zip_filename} ({zip_size:.1f} KB)\")\n",
    "        try:\n",
    "            from IPython.display import FileLink\n",
    "            print(\"üì• Download link: \", end=\"\")\n",
    "            display(FileLink(zip_filename))\n",
    "        except:\n",
    "            print(f\"üì• File saved at: {os.path.abspath(zip_filename)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No files found to zip\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not create zip file: {e}\")\n",
    "    print(f\"üìÅ Files are in: {os.getcwd()}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9388759,
     "sourceId": 14698190,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.766023,
   "end_time": "2026-02-01T15:01:55.975655",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-01T15:01:30.209632",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
